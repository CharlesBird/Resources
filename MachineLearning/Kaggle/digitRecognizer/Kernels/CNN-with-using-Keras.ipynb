{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['digit-recognizer.zip', 'sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(os.listdir(\"../data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../data/train.csv\")\n",
    "y_train = X_train.label\n",
    "X_train = X_train.drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= X_train.max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values.reshape(-1,28,28,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(8, 8, figsize=(6, 6))\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(X_train[i, :, :, 0], cmap='binary')\n",
    "    axi.set(xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41968</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41969</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41970</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41972</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41973</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41974</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41975</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41976</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41977</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41978</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41982</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41986</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41988</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41991</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37800 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9\n",
       "0      0  1  0  0  0  0  0  0  0  0\n",
       "2      0  1  0  0  0  0  0  0  0  0\n",
       "3      0  0  0  0  1  0  0  0  0  0\n",
       "4      1  0  0  0  0  0  0  0  0  0\n",
       "6      0  0  0  0  0  0  0  1  0  0\n",
       "7      0  0  0  1  0  0  0  0  0  0\n",
       "8      0  0  0  0  0  1  0  0  0  0\n",
       "9      0  0  0  1  0  0  0  0  0  0\n",
       "10     0  0  0  0  0  0  0  0  1  0\n",
       "12     0  1  0  0  0  0  0  0  0  0\n",
       "13     0  0  0  1  0  0  0  0  0  0\n",
       "14     0  0  0  1  0  0  0  0  0  0\n",
       "15     0  1  0  0  0  0  0  0  0  0\n",
       "16     0  0  1  0  0  0  0  0  0  0\n",
       "17     1  0  0  0  0  0  0  0  0  0\n",
       "18     0  0  0  0  0  0  0  1  0  0\n",
       "20     0  0  0  0  0  0  0  0  1  0\n",
       "21     0  0  0  0  0  0  1  0  0  0\n",
       "22     0  0  1  0  0  0  0  0  0  0\n",
       "23     1  0  0  0  0  0  0  0  0  0\n",
       "24     0  0  1  0  0  0  0  0  0  0\n",
       "25     0  0  0  1  0  0  0  0  0  0\n",
       "26     0  0  0  0  0  0  1  0  0  0\n",
       "27     0  0  0  0  0  0  0  0  0  1\n",
       "28     0  0  0  0  0  0  0  0  0  1\n",
       "29     0  0  0  0  0  0  0  1  0  0\n",
       "31     0  0  0  0  0  0  0  0  0  1\n",
       "32     0  0  0  0  1  0  0  0  0  0\n",
       "33     0  0  0  0  0  0  0  0  0  1\n",
       "35     0  1  0  0  0  0  0  0  0  0\n",
       "...   .. .. .. .. .. .. .. .. .. ..\n",
       "41968  1  0  0  0  0  0  0  0  0  0\n",
       "41969  0  0  0  0  0  0  0  0  0  1\n",
       "41970  0  0  1  0  0  0  0  0  0  0\n",
       "41972  0  0  0  0  1  0  0  0  0  0\n",
       "41973  0  0  0  0  1  0  0  0  0  0\n",
       "41974  0  0  0  1  0  0  0  0  0  0\n",
       "41975  0  0  0  0  0  0  0  0  0  1\n",
       "41976  0  0  1  0  0  0  0  0  0  0\n",
       "41977  0  0  0  0  1  0  0  0  0  0\n",
       "41978  0  0  0  0  1  0  0  0  0  0\n",
       "41979  0  0  0  0  1  0  0  0  0  0\n",
       "41980  0  0  0  0  0  0  0  1  0  0\n",
       "41982  0  0  0  0  0  0  0  0  1  0\n",
       "41983  0  0  0  0  0  0  0  1  0  0\n",
       "41984  0  0  0  1  0  0  0  0  0  0\n",
       "41985  0  0  0  1  0  0  0  0  0  0\n",
       "41986  1  0  0  0  0  0  0  0  0  0\n",
       "41987  0  0  0  0  0  1  0  0  0  0\n",
       "41988  1  0  0  0  0  0  0  0  0  0\n",
       "41989  0  0  0  0  0  1  0  0  0  0\n",
       "41990  0  0  0  1  0  0  0  0  0  0\n",
       "41991  0  1  0  0  0  0  0  0  0  0\n",
       "41992  0  0  0  0  0  0  0  0  0  1\n",
       "41993  0  0  0  0  0  0  1  0  0  0\n",
       "41994  0  0  0  0  1  0  0  0  0  0\n",
       "41995  1  0  0  0  0  0  0  0  0  0\n",
       "41996  0  1  0  0  0  0  0  0  0  0\n",
       "41997  0  0  0  0  0  0  0  1  0  0\n",
       "41998  0  0  0  0  0  0  1  0  0  0\n",
       "41999  0  0  0  0  0  0  0  0  0  1\n",
       "\n",
       "[37800 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx = np.random.choice(range(X_train.shape[0]), int(X_train.shape[0] * 0.1), replace=False)\n",
    "train_idx = [i for i in range(X_train.shape[0]) if i not in test_idx]\n",
    "X_test = X_train[test_idx]\n",
    "y_test = pd.get_dummies(y_train[test_idx])\n",
    "X_train = X_train[train_idx]\n",
    "y_train = pd.get_dummies(y_train[train_idx])\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\PythonDevelopers\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Users\\PythonDevelopers\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 1, 128)         131200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 271,018\n",
      "Trainable params: 271,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=X_train[0].shape))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (4, 4), activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\PythonDevelopers\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/1000\n",
      "34020/34020 [==============================] - 31s 925us/step - loss: 0.8677 - acc: 0.7102 - val_loss: 0.2074 - val_acc: 0.9373\n",
      "Epoch 2/1000\n",
      "34020/34020 [==============================] - 30s 875us/step - loss: 0.1932 - acc: 0.9474 - val_loss: 0.0895 - val_acc: 0.9728\n",
      "Epoch 3/1000\n",
      "34020/34020 [==============================] - 30s 878us/step - loss: 0.1201 - acc: 0.9686 - val_loss: 0.0856 - val_acc: 0.9767\n",
      "Epoch 4/1000\n",
      "34020/34020 [==============================] - 30s 886us/step - loss: 0.0931 - acc: 0.9750 - val_loss: 0.0639 - val_acc: 0.9799\n",
      "Epoch 5/1000\n",
      "34020/34020 [==============================] - 31s 903us/step - loss: 0.0737 - acc: 0.9812 - val_loss: 0.0344 - val_acc: 0.9889\n",
      "Epoch 6/1000\n",
      "34020/34020 [==============================] - 30s 888us/step - loss: 0.0653 - acc: 0.9831 - val_loss: 0.0500 - val_acc: 0.9847\n",
      "Epoch 7/1000\n",
      "34020/34020 [==============================] - 30s 886us/step - loss: 0.0531 - acc: 0.9859 - val_loss: 0.0389 - val_acc: 0.9881\n",
      "Epoch 8/1000\n",
      "34020/34020 [==============================] - 31s 898us/step - loss: 0.0531 - acc: 0.9865 - val_loss: 0.0420 - val_acc: 0.9889\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef80aed5c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=320, epochs=1000, verbose=1,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[EarlyStopping(monitor='val_acc', patience=3,\n",
    "                                   verbose=1, mode='auto', restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.82486230e-08, 8.25378450e-08, 9.17425691e-09, ...,\n",
       "        2.85986662e-05, 1.03775055e-05, 9.99916196e-01],\n",
       "       [4.77252725e-05, 6.76714990e-05, 3.10407122e-05, ...,\n",
       "        1.09610322e-03, 8.93381075e-04, 9.84532058e-01],\n",
       "       [3.62447821e-07, 2.10831459e-07, 1.73526814e-07, ...,\n",
       "        3.18496006e-07, 1.22437787e-05, 2.44128823e-05],\n",
       "       ...,\n",
       "       [1.56220480e-07, 5.35976152e-09, 1.73707870e-09, ...,\n",
       "        3.80263931e-10, 2.61844435e-09, 1.45055259e-10],\n",
       "       [7.00670284e-07, 6.13839646e-08, 1.59752886e-08, ...,\n",
       "        2.95273095e-09, 2.29558914e-08, 1.22467092e-09],\n",
       "       [2.30383785e-06, 1.19015085e-05, 8.05664331e-06, ...,\n",
       "        1.27705187e-06, 9.99892116e-01, 4.52011955e-05]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>447</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>351</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>435</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>418</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1    2    3    4    5    6    7    8    9\n",
       "row_0                                                  \n",
       "0      389    0    0    0    0    0    0    0    0    2\n",
       "1        0  474    0    0    0    0    1    2    0    0\n",
       "2        0    1  447    1    1    0    0    3    0    0\n",
       "3        1    0    1  413    0    0    1    0    2    0\n",
       "4        0    0    2    0  379    0    0    1    1    4\n",
       "5        0    0    0    0    0  351    3    0    1    0\n",
       "6        1    0    0    0    0    0  435    0    2    0\n",
       "7        0    0    1    0    0    0    0  459    0    0\n",
       "8        0    0    3    0    0    1    0    0  418    3\n",
       "9        1    1    0    0    1    1    0    1    1  390"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test).argmax(axis=1)\n",
    "pd.crosstab(y_test.idxmax(axis=1), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9892857142857143"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test.idxmax(axis=1) == preds).sum() / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/1000\n",
      "34020/34020 [==============================] - 31s 919us/step - loss: 0.8047 - acc: 0.7336 - val_loss: 0.1419 - val_acc: 0.9579\n",
      "Epoch 2/1000\n",
      "34020/34020 [==============================] - 30s 892us/step - loss: 0.1923 - acc: 0.9484 - val_loss: 0.1091 - val_acc: 0.9698\n",
      "Epoch 3/1000\n",
      "34020/34020 [==============================] - 31s 902us/step - loss: 0.1206 - acc: 0.9690 - val_loss: 0.0817 - val_acc: 0.9778\n",
      "Epoch 4/1000\n",
      "34020/34020 [==============================] - 31s 901us/step - loss: 0.0945 - acc: 0.9762 - val_loss: 0.0669 - val_acc: 0.9810\n",
      "Epoch 5/1000\n",
      "34020/34020 [==============================] - 31s 915us/step - loss: 0.0786 - acc: 0.9799 - val_loss: 0.1131 - val_acc: 0.9672\n",
      "Epoch 6/1000\n",
      "34020/34020 [==============================] - 31s 923us/step - loss: 0.0669 - acc: 0.9828 - val_loss: 0.0459 - val_acc: 0.9857\n",
      "Epoch 7/1000\n",
      "34020/34020 [==============================] - 32s 932us/step - loss: 0.0570 - acc: 0.9855 - val_loss: 0.0492 - val_acc: 0.9860\n",
      "Epoch 8/1000\n",
      "34020/34020 [==============================] - 32s 939us/step - loss: 0.0526 - acc: 0.9866 - val_loss: 0.0425 - val_acc: 0.9881\n",
      "Epoch 9/1000\n",
      "34020/34020 [==============================] - 32s 948us/step - loss: 0.0458 - acc: 0.9884 - val_loss: 0.0631 - val_acc: 0.9852\n",
      "Epoch 10/1000\n",
      "34020/34020 [==============================] - 32s 945us/step - loss: 0.0427 - acc: 0.9889 - val_loss: 0.0356 - val_acc: 0.9905\n",
      "Epoch 11/1000\n",
      "34020/34020 [==============================] - 33s 973us/step - loss: 0.0388 - acc: 0.9900 - val_loss: 0.0358 - val_acc: 0.9913\n",
      "Epoch 12/1000\n",
      "34020/34020 [==============================] - 33s 965us/step - loss: 0.0384 - acc: 0.9904 - val_loss: 0.0300 - val_acc: 0.9910\n",
      "Epoch 13/1000\n",
      "34020/34020 [==============================] - 33s 959us/step - loss: 0.0328 - acc: 0.9911 - val_loss: 0.0336 - val_acc: 0.9918\n",
      "Epoch 14/1000\n",
      "34020/34020 [==============================] - 33s 957us/step - loss: 0.0323 - acc: 0.9915 - val_loss: 0.0315 - val_acc: 0.9926\n",
      "Epoch 15/1000\n",
      "34020/34020 [==============================] - 33s 960us/step - loss: 0.0321 - acc: 0.9923 - val_loss: 0.0435 - val_acc: 0.9907\n",
      "Epoch 16/1000\n",
      "34020/34020 [==============================] - 33s 962us/step - loss: 0.0300 - acc: 0.9927 - val_loss: 0.0490 - val_acc: 0.9886\n",
      "Epoch 17/1000\n",
      "34020/34020 [==============================] - 33s 961us/step - loss: 0.0298 - acc: 0.9928 - val_loss: 0.0345 - val_acc: 0.9921\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00017: early stopping\n",
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/1000\n",
      "34020/34020 [==============================] - 35s 1ms/step - loss: 0.8103 - acc: 0.7284 - val_loss: 0.1471 - val_acc: 0.9540\n",
      "Epoch 2/1000\n",
      "34020/34020 [==============================] - 33s 978us/step - loss: 0.1920 - acc: 0.9480 - val_loss: 0.0998 - val_acc: 0.9717\n",
      "Epoch 3/1000\n",
      "34020/34020 [==============================] - 33s 978us/step - loss: 0.1217 - acc: 0.9672 - val_loss: 0.0609 - val_acc: 0.9825\n",
      "Epoch 4/1000\n",
      "34020/34020 [==============================] - 33s 975us/step - loss: 0.0964 - acc: 0.9754 - val_loss: 0.0616 - val_acc: 0.9815\n",
      "Epoch 5/1000\n",
      "34020/34020 [==============================] - 33s 969us/step - loss: 0.0779 - acc: 0.9800 - val_loss: 0.0566 - val_acc: 0.9868\n",
      "Epoch 6/1000\n",
      "34020/34020 [==============================] - 33s 969us/step - loss: 0.0679 - acc: 0.9831 - val_loss: 0.0459 - val_acc: 0.9884\n",
      "Epoch 7/1000\n",
      "34020/34020 [==============================] - 33s 974us/step - loss: 0.0582 - acc: 0.9840 - val_loss: 0.0439 - val_acc: 0.9884\n",
      "Epoch 8/1000\n",
      "34020/34020 [==============================] - 33s 974us/step - loss: 0.0533 - acc: 0.9863 - val_loss: 0.0487 - val_acc: 0.9868\n",
      "Epoch 9/1000\n",
      "34020/34020 [==============================] - 33s 981us/step - loss: 0.0458 - acc: 0.9876 - val_loss: 0.0382 - val_acc: 0.9918\n",
      "Epoch 10/1000\n",
      "34020/34020 [==============================] - 33s 984us/step - loss: 0.0412 - acc: 0.9896 - val_loss: 0.0412 - val_acc: 0.9915\n",
      "Epoch 11/1000\n",
      "34020/34020 [==============================] - 33s 977us/step - loss: 0.0424 - acc: 0.9894 - val_loss: 0.0393 - val_acc: 0.9913\n",
      "Epoch 12/1000\n",
      "34020/34020 [==============================] - 33s 979us/step - loss: 0.0396 - acc: 0.9902 - val_loss: 0.0378 - val_acc: 0.9918\n",
      "Epoch 13/1000\n",
      "34020/34020 [==============================] - 33s 967us/step - loss: 0.0357 - acc: 0.9907 - val_loss: 0.0429 - val_acc: 0.9913\n",
      "Epoch 14/1000\n",
      "34020/34020 [==============================] - 33s 967us/step - loss: 0.0343 - acc: 0.9909 - val_loss: 0.0388 - val_acc: 0.9902\n",
      "Epoch 15/1000\n",
      "34020/34020 [==============================] - 33s 968us/step - loss: 0.0324 - acc: 0.9913 - val_loss: 0.0515 - val_acc: 0.9894\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00015: early stopping\n",
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/1000\n",
      "34020/34020 [==============================] - 34s 1000us/step - loss: 0.9103 - acc: 0.6903 - val_loss: 0.1797 - val_acc: 0.9497\n",
      "Epoch 2/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.2062 - acc: 0.9444 - val_loss: 0.0935 - val_acc: 0.9728\n",
      "Epoch 3/1000\n",
      "34020/34020 [==============================] - 33s 977us/step - loss: 0.1230 - acc: 0.9671 - val_loss: 0.0587 - val_acc: 0.9825\n",
      "Epoch 4/1000\n",
      "34020/34020 [==============================] - 33s 979us/step - loss: 0.0927 - acc: 0.9756 - val_loss: 0.0513 - val_acc: 0.9833\n",
      "Epoch 5/1000\n",
      "34020/34020 [==============================] - 34s 995us/step - loss: 0.0793 - acc: 0.9799 - val_loss: 0.0627 - val_acc: 0.9799\n",
      "Epoch 6/1000\n",
      "34020/34020 [==============================] - 33s 977us/step - loss: 0.0634 - acc: 0.9834 - val_loss: 0.0458 - val_acc: 0.9881\n",
      "Epoch 7/1000\n",
      "34020/34020 [==============================] - 33s 977us/step - loss: 0.0581 - acc: 0.9850 - val_loss: 0.0413 - val_acc: 0.9889\n",
      "Epoch 8/1000\n",
      "34020/34020 [==============================] - 33s 981us/step - loss: 0.0517 - acc: 0.9871 - val_loss: 0.0368 - val_acc: 0.9892\n",
      "Epoch 9/1000\n",
      "34020/34020 [==============================] - 33s 980us/step - loss: 0.0465 - acc: 0.9877 - val_loss: 0.0339 - val_acc: 0.9923\n",
      "Epoch 10/1000\n",
      "34020/34020 [==============================] - 34s 987us/step - loss: 0.0470 - acc: 0.9882 - val_loss: 0.0460 - val_acc: 0.9854\n",
      "Epoch 11/1000\n",
      "34020/34020 [==============================] - 34s 990us/step - loss: 0.0429 - acc: 0.9889 - val_loss: 0.0275 - val_acc: 0.9907\n",
      "Epoch 12/1000\n",
      "34020/34020 [==============================] - 34s 992us/step - loss: 0.0382 - acc: 0.9904 - val_loss: 0.0471 - val_acc: 0.9881\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00012: early stopping\n",
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/1000\n",
      "34020/34020 [==============================] - 35s 1ms/step - loss: 0.8472 - acc: 0.7198 - val_loss: 0.1326 - val_acc: 0.9614\n",
      "Epoch 2/1000\n",
      "34020/34020 [==============================] - 33s 980us/step - loss: 0.1863 - acc: 0.9496 - val_loss: 0.0930 - val_acc: 0.9735\n",
      "Epoch 3/1000\n",
      "34020/34020 [==============================] - 33s 980us/step - loss: 0.1194 - acc: 0.9689 - val_loss: 0.0872 - val_acc: 0.9746\n",
      "Epoch 4/1000\n",
      "34020/34020 [==============================] - 33s 984us/step - loss: 0.0920 - acc: 0.9760 - val_loss: 0.0635 - val_acc: 0.9833\n",
      "Epoch 5/1000\n",
      "34020/34020 [==============================] - 33s 977us/step - loss: 0.0737 - acc: 0.9807 - val_loss: 0.0670 - val_acc: 0.9831\n",
      "Epoch 6/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.0649 - acc: 0.9829 - val_loss: 0.0560 - val_acc: 0.9844\n",
      "Epoch 7/1000\n",
      "34020/34020 [==============================] - 33s 982us/step - loss: 0.0550 - acc: 0.9854 - val_loss: 0.0311 - val_acc: 0.9899\n",
      "Epoch 8/1000\n",
      "34020/34020 [==============================] - 33s 978us/step - loss: 0.0514 - acc: 0.9862 - val_loss: 0.0511 - val_acc: 0.9865\n",
      "Epoch 9/1000\n",
      "34020/34020 [==============================] - 33s 982us/step - loss: 0.0450 - acc: 0.9887 - val_loss: 0.0314 - val_acc: 0.9913\n",
      "Epoch 10/1000\n",
      "34020/34020 [==============================] - 33s 983us/step - loss: 0.0423 - acc: 0.9886 - val_loss: 0.0494 - val_acc: 0.9881\n",
      "Epoch 11/1000\n",
      "34020/34020 [==============================] - 33s 980us/step - loss: 0.0389 - acc: 0.9895 - val_loss: 0.0380 - val_acc: 0.9915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000\n",
      "34020/34020 [==============================] - 33s 981us/step - loss: 0.0402 - acc: 0.9897 - val_loss: 0.0295 - val_acc: 0.9910\n",
      "Epoch 13/1000\n",
      "34020/34020 [==============================] - 34s 995us/step - loss: 0.0347 - acc: 0.9916 - val_loss: 0.0365 - val_acc: 0.9907\n",
      "Epoch 14/1000\n",
      "34020/34020 [==============================] - 34s 995us/step - loss: 0.0316 - acc: 0.9929 - val_loss: 0.0356 - val_acc: 0.9923\n",
      "Epoch 15/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.0323 - acc: 0.9917 - val_loss: 0.0474 - val_acc: 0.9902\n",
      "Epoch 16/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.0301 - acc: 0.9926 - val_loss: 0.0324 - val_acc: 0.9918\n",
      "Epoch 17/1000\n",
      "34020/34020 [==============================] - 36s 1ms/step - loss: 0.0276 - acc: 0.9924 - val_loss: 0.0334 - val_acc: 0.9923\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00017: early stopping\n",
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/1000\n",
      "34020/34020 [==============================] - 35s 1ms/step - loss: 0.8532 - acc: 0.7177 - val_loss: 0.2061 - val_acc: 0.9392\n",
      "Epoch 2/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.1891 - acc: 0.9478 - val_loss: 0.1334 - val_acc: 0.9643\n",
      "Epoch 3/1000\n",
      "34020/34020 [==============================] - 35s 1ms/step - loss: 0.1199 - acc: 0.9687 - val_loss: 0.0838 - val_acc: 0.9749\n",
      "Epoch 4/1000\n",
      "34020/34020 [==============================] - 37s 1ms/step - loss: 0.0941 - acc: 0.9756 - val_loss: 0.0496 - val_acc: 0.9852\n",
      "Epoch 5/1000\n",
      "34020/34020 [==============================] - 35s 1ms/step - loss: 0.0741 - acc: 0.9804 - val_loss: 0.0499 - val_acc: 0.9862\n",
      "Epoch 6/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.0675 - acc: 0.9823 - val_loss: 0.0634 - val_acc: 0.9841\n",
      "Epoch 7/1000\n",
      "34020/34020 [==============================] - 34s 988us/step - loss: 0.0603 - acc: 0.9840 - val_loss: 0.0547 - val_acc: 0.9860\n",
      "Epoch 8/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.0535 - acc: 0.9863 - val_loss: 0.0477 - val_acc: 0.9876\n",
      "Epoch 9/1000\n",
      "34020/34020 [==============================] - 34s 991us/step - loss: 0.0491 - acc: 0.9882 - val_loss: 0.0445 - val_acc: 0.9902\n",
      "Epoch 10/1000\n",
      "34020/34020 [==============================] - 34s 990us/step - loss: 0.0466 - acc: 0.9890 - val_loss: 0.0455 - val_acc: 0.9892\n",
      "Epoch 11/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.0429 - acc: 0.9890 - val_loss: 0.0642 - val_acc: 0.9852\n",
      "Epoch 12/1000\n",
      "34020/34020 [==============================] - 34s 996us/step - loss: 0.0403 - acc: 0.9897 - val_loss: 0.0343 - val_acc: 0.9918\n",
      "Epoch 13/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.0366 - acc: 0.9904 - val_loss: 0.0349 - val_acc: 0.9907\n",
      "Epoch 14/1000\n",
      "34020/34020 [==============================] - 33s 983us/step - loss: 0.0353 - acc: 0.9913 - val_loss: 0.0310 - val_acc: 0.9921\n",
      "Epoch 15/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.0314 - acc: 0.9916 - val_loss: 0.0337 - val_acc: 0.9929\n",
      "Epoch 16/1000\n",
      "34020/34020 [==============================] - 34s 995us/step - loss: 0.0312 - acc: 0.9923 - val_loss: 0.0387 - val_acc: 0.9915\n",
      "Epoch 17/1000\n",
      "34020/34020 [==============================] - 34s 990us/step - loss: 0.0305 - acc: 0.9923 - val_loss: 0.0310 - val_acc: 0.9931\n",
      "Epoch 18/1000\n",
      "34020/34020 [==============================] - 34s 987us/step - loss: 0.0259 - acc: 0.9934 - val_loss: 0.0278 - val_acc: 0.9923\n",
      "Epoch 19/1000\n",
      "34020/34020 [==============================] - 34s 996us/step - loss: 0.0258 - acc: 0.9929 - val_loss: 0.0332 - val_acc: 0.9915\n",
      "Epoch 20/1000\n",
      "34020/34020 [==============================] - 33s 984us/step - loss: 0.0267 - acc: 0.9929 - val_loss: 0.0379 - val_acc: 0.9913\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00020: early stopping\n",
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/1000\n",
      "34020/34020 [==============================] - 35s 1ms/step - loss: 0.9477 - acc: 0.6839 - val_loss: 0.1947 - val_acc: 0.9452\n",
      "Epoch 2/1000\n",
      "34020/34020 [==============================] - 33s 983us/step - loss: 0.2115 - acc: 0.9449 - val_loss: 0.1258 - val_acc: 0.9646\n",
      "Epoch 3/1000\n",
      "34020/34020 [==============================] - 33s 984us/step - loss: 0.1313 - acc: 0.9658 - val_loss: 0.0758 - val_acc: 0.9810\n",
      "Epoch 4/1000\n",
      "34020/34020 [==============================] - 34s 998us/step - loss: 0.0947 - acc: 0.9765 - val_loss: 0.0579 - val_acc: 0.9825\n",
      "Epoch 5/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.0775 - acc: 0.9804 - val_loss: 0.0572 - val_acc: 0.9841\n",
      "Epoch 6/1000\n",
      "34020/34020 [==============================] - 34s 993us/step - loss: 0.0655 - acc: 0.9825 - val_loss: 0.0385 - val_acc: 0.9889\n",
      "Epoch 7/1000\n",
      "34020/34020 [==============================] - 34s 988us/step - loss: 0.0581 - acc: 0.9849 - val_loss: 0.0424 - val_acc: 0.9892\n",
      "Epoch 8/1000\n",
      "34020/34020 [==============================] - 34s 997us/step - loss: 0.0566 - acc: 0.9858 - val_loss: 0.0473 - val_acc: 0.9876\n",
      "Epoch 9/1000\n",
      "34020/34020 [==============================] - 34s 995us/step - loss: 0.0464 - acc: 0.9883 - val_loss: 0.0404 - val_acc: 0.9894\n",
      "Epoch 10/1000\n",
      "34020/34020 [==============================] - 33s 980us/step - loss: 0.0460 - acc: 0.9880 - val_loss: 0.0449 - val_acc: 0.9892\n",
      "Epoch 11/1000\n",
      "34020/34020 [==============================] - 33s 976us/step - loss: 0.0434 - acc: 0.9889 - val_loss: 0.0341 - val_acc: 0.9913\n",
      "Epoch 12/1000\n",
      "34020/34020 [==============================] - 33s 974us/step - loss: 0.0378 - acc: 0.9903 - val_loss: 0.0337 - val_acc: 0.9910\n",
      "Epoch 13/1000\n",
      "34020/34020 [==============================] - 33s 975us/step - loss: 0.0354 - acc: 0.9904 - val_loss: 0.0316 - val_acc: 0.9918\n",
      "Epoch 14/1000\n",
      "34020/34020 [==============================] - 33s 977us/step - loss: 0.0336 - acc: 0.9911 - val_loss: 0.0312 - val_acc: 0.9918\n",
      "Epoch 15/1000\n",
      "34020/34020 [==============================] - 33s 972us/step - loss: 0.0340 - acc: 0.9912 - val_loss: 0.0269 - val_acc: 0.9931\n",
      "Epoch 16/1000\n",
      "34020/34020 [==============================] - 33s 973us/step - loss: 0.0290 - acc: 0.9923 - val_loss: 0.0386 - val_acc: 0.9918\n",
      "Epoch 17/1000\n",
      "34020/34020 [==============================] - 33s 973us/step - loss: 0.0301 - acc: 0.9922 - val_loss: 0.0312 - val_acc: 0.9910\n",
      "Epoch 18/1000\n",
      "34020/34020 [==============================] - 33s 973us/step - loss: 0.0291 - acc: 0.9923 - val_loss: 0.0270 - val_acc: 0.9929\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00018: early stopping\n",
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.8265 - acc: 0.7198 - val_loss: 0.1719 - val_acc: 0.9508\n",
      "Epoch 2/1000\n",
      "34020/34020 [==============================] - 33s 975us/step - loss: 0.1866 - acc: 0.9489 - val_loss: 0.0984 - val_acc: 0.9714\n",
      "Epoch 3/1000\n",
      "34020/34020 [==============================] - 33s 971us/step - loss: 0.1207 - acc: 0.9684 - val_loss: 0.0664 - val_acc: 0.9810\n",
      "Epoch 4/1000\n",
      "34020/34020 [==============================] - 33s 972us/step - loss: 0.0961 - acc: 0.9751 - val_loss: 0.0540 - val_acc: 0.9839\n",
      "Epoch 5/1000\n",
      "34020/34020 [==============================] - 33s 972us/step - loss: 0.0778 - acc: 0.9797 - val_loss: 0.0572 - val_acc: 0.9828\n",
      "Epoch 6/1000\n",
      "34020/34020 [==============================] - 33s 973us/step - loss: 0.0657 - acc: 0.9837 - val_loss: 0.0465 - val_acc: 0.9854\n",
      "Epoch 7/1000\n",
      "34020/34020 [==============================] - 33s 971us/step - loss: 0.0594 - acc: 0.9850 - val_loss: 0.0531 - val_acc: 0.9849\n",
      "Epoch 8/1000\n",
      "34020/34020 [==============================] - 33s 971us/step - loss: 0.0536 - acc: 0.9859 - val_loss: 0.0436 - val_acc: 0.9897\n",
      "Epoch 9/1000\n",
      "34020/34020 [==============================] - 33s 971us/step - loss: 0.0463 - acc: 0.9878 - val_loss: 0.0362 - val_acc: 0.9910\n",
      "Epoch 10/1000\n",
      "34020/34020 [==============================] - 33s 972us/step - loss: 0.0429 - acc: 0.9891 - val_loss: 0.0390 - val_acc: 0.9902\n",
      "Epoch 11/1000\n",
      "34020/34020 [==============================] - 33s 974us/step - loss: 0.0429 - acc: 0.9892 - val_loss: 0.0336 - val_acc: 0.9929\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34020/34020 [==============================] - 33s 973us/step - loss: 0.0385 - acc: 0.9902 - val_loss: 0.0371 - val_acc: 0.9907\n",
      "Epoch 13/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.0368 - acc: 0.9910 - val_loss: 0.0337 - val_acc: 0.9923\n",
      "Epoch 14/1000\n",
      "34020/34020 [==============================] - 33s 969us/step - loss: 0.0332 - acc: 0.9912 - val_loss: 0.0434 - val_acc: 0.9894\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00014: early stopping\n",
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.7888 - acc: 0.7438 - val_loss: 0.2116 - val_acc: 0.9378\n",
      "Epoch 2/1000\n",
      "34020/34020 [==============================] - 33s 972us/step - loss: 0.1983 - acc: 0.9474 - val_loss: 0.1426 - val_acc: 0.9585\n",
      "Epoch 3/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.1259 - acc: 0.9667 - val_loss: 0.0721 - val_acc: 0.9780\n",
      "Epoch 4/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.0927 - acc: 0.9767 - val_loss: 0.0704 - val_acc: 0.9810\n",
      "Epoch 5/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.0801 - acc: 0.9796 - val_loss: 0.0574 - val_acc: 0.9833\n",
      "Epoch 6/1000\n",
      "34020/34020 [==============================] - 33s 976us/step - loss: 0.0705 - acc: 0.9810 - val_loss: 0.0538 - val_acc: 0.9844\n",
      "Epoch 7/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.0590 - acc: 0.9855 - val_loss: 0.0429 - val_acc: 0.9881\n",
      "Epoch 8/1000\n",
      "34020/34020 [==============================] - 33s 974us/step - loss: 0.0560 - acc: 0.9861 - val_loss: 0.0449 - val_acc: 0.9865\n",
      "Epoch 9/1000\n",
      "34020/34020 [==============================] - 33s 969us/step - loss: 0.0509 - acc: 0.9867 - val_loss: 0.0449 - val_acc: 0.9884\n",
      "Epoch 10/1000\n",
      "34020/34020 [==============================] - 33s 969us/step - loss: 0.0446 - acc: 0.9883 - val_loss: 0.0594 - val_acc: 0.9868\n",
      "Epoch 11/1000\n",
      "34020/34020 [==============================] - 33s 971us/step - loss: 0.0408 - acc: 0.9894 - val_loss: 0.0328 - val_acc: 0.9921\n",
      "Epoch 12/1000\n",
      "34020/34020 [==============================] - 33s 971us/step - loss: 0.0383 - acc: 0.9903 - val_loss: 0.0475 - val_acc: 0.9897\n",
      "Epoch 13/1000\n",
      "34020/34020 [==============================] - 33s 973us/step - loss: 0.0363 - acc: 0.9911 - val_loss: 0.0309 - val_acc: 0.9918\n",
      "Epoch 14/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.0349 - acc: 0.9914 - val_loss: 0.0523 - val_acc: 0.9915\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00014: early stopping\n",
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/1000\n",
      "34020/34020 [==============================] - 34s 1ms/step - loss: 0.9369 - acc: 0.6815 - val_loss: 0.1640 - val_acc: 0.9508\n",
      "Epoch 2/1000\n",
      "34020/34020 [==============================] - 33s 967us/step - loss: 0.2013 - acc: 0.9453 - val_loss: 0.1041 - val_acc: 0.9680\n",
      "Epoch 3/1000\n",
      "34020/34020 [==============================] - 33s 969us/step - loss: 0.1164 - acc: 0.9696 - val_loss: 0.0808 - val_acc: 0.9778\n",
      "Epoch 4/1000\n",
      "34020/34020 [==============================] - 33s 969us/step - loss: 0.0971 - acc: 0.9742 - val_loss: 0.0583 - val_acc: 0.9815\n",
      "Epoch 5/1000\n",
      "34020/34020 [==============================] - 33s 971us/step - loss: 0.0763 - acc: 0.9810 - val_loss: 0.0587 - val_acc: 0.9852\n",
      "Epoch 6/1000\n",
      "34020/34020 [==============================] - 33s 974us/step - loss: 0.0632 - acc: 0.9840 - val_loss: 0.0469 - val_acc: 0.9857\n",
      "Epoch 7/1000\n",
      "34020/34020 [==============================] - 33s 978us/step - loss: 0.0574 - acc: 0.9851 - val_loss: 0.0577 - val_acc: 0.9847\n",
      "Epoch 8/1000\n",
      "34020/34020 [==============================] - 33s 971us/step - loss: 0.0547 - acc: 0.9862 - val_loss: 0.0628 - val_acc: 0.9852\n",
      "Epoch 9/1000\n",
      "34020/34020 [==============================] - 33s 972us/step - loss: 0.0475 - acc: 0.9878 - val_loss: 0.0488 - val_acc: 0.9868\n",
      "Epoch 10/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.0447 - acc: 0.9886 - val_loss: 0.0418 - val_acc: 0.9894\n",
      "Epoch 11/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.0399 - acc: 0.9899 - val_loss: 0.0532 - val_acc: 0.9862\n",
      "Epoch 12/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.0402 - acc: 0.9899 - val_loss: 0.0315 - val_acc: 0.9913\n",
      "Epoch 13/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.0346 - acc: 0.9914 - val_loss: 0.0455 - val_acc: 0.9860\n",
      "Epoch 14/1000\n",
      "34020/34020 [==============================] - 33s 971us/step - loss: 0.0312 - acc: 0.9918 - val_loss: 0.0319 - val_acc: 0.9910\n",
      "Epoch 15/1000\n",
      "34020/34020 [==============================] - 33s 973us/step - loss: 0.0333 - acc: 0.9918 - val_loss: 0.0464 - val_acc: 0.9860\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00015: early stopping\n",
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/1000\n",
      "34020/34020 [==============================] - 35s 1ms/step - loss: 0.8287 - acc: 0.7225 - val_loss: 0.1646 - val_acc: 0.9471\n",
      "Epoch 2/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.1929 - acc: 0.9479 - val_loss: 0.0912 - val_acc: 0.9749\n",
      "Epoch 3/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.1229 - acc: 0.9670 - val_loss: 0.0753 - val_acc: 0.9783\n",
      "Epoch 4/1000\n",
      "34020/34020 [==============================] - 33s 968us/step - loss: 0.0955 - acc: 0.9748 - val_loss: 0.0688 - val_acc: 0.9807\n",
      "Epoch 5/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.0766 - acc: 0.9797 - val_loss: 0.0491 - val_acc: 0.9870\n",
      "Epoch 6/1000\n",
      "34020/34020 [==============================] - 33s 973us/step - loss: 0.0675 - acc: 0.9821 - val_loss: 0.0357 - val_acc: 0.9886\n",
      "Epoch 7/1000\n",
      "34020/34020 [==============================] - 33s 971us/step - loss: 0.0565 - acc: 0.9856 - val_loss: 0.0605 - val_acc: 0.9825\n",
      "Epoch 8/1000\n",
      "34020/34020 [==============================] - 33s 974us/step - loss: 0.0535 - acc: 0.9856 - val_loss: 0.0446 - val_acc: 0.9881\n",
      "Epoch 9/1000\n",
      "34020/34020 [==============================] - 33s 970us/step - loss: 0.0482 - acc: 0.9873 - val_loss: 0.0293 - val_acc: 0.9915\n",
      "Epoch 10/1000\n",
      "34020/34020 [==============================] - 33s 975us/step - loss: 0.0412 - acc: 0.9902 - val_loss: 0.0585 - val_acc: 0.9876\n",
      "Epoch 11/1000\n",
      "34020/34020 [==============================] - 33s 973us/step - loss: 0.0445 - acc: 0.9887 - val_loss: 0.0326 - val_acc: 0.9907\n",
      "Epoch 12/1000\n",
      "34020/34020 [==============================] - 33s 976us/step - loss: 0.0358 - acc: 0.9904 - val_loss: 0.0482 - val_acc: 0.9886\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "test_probs = []\n",
    "for i in range(10):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=X_train[0].shape))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, (4, 4), activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=320, epochs=1000, verbose=1,\n",
    "              validation_split=0.1,\n",
    "              callbacks=[EarlyStopping(monitor='val_acc', patience=3,\n",
    "                                       verbose=1, mode='auto', restore_best_weights=True)])\n",
    "    \n",
    "    test_probs.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>383</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>352</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1    2    3    4    5    6    7    8    9\n",
       "row_0                                                  \n",
       "0      390    0    1    0    0    0    0    0    0    0\n",
       "1        0  474    0    0    0    0    1    2    0    0\n",
       "2        0    0  451    0    1    0    0    1    0    0\n",
       "3        0    0    0  415    0    0    0    0    3    0\n",
       "4        0    0    2    0  383    0    0    0    2    0\n",
       "5        0    0    0    0    0  352    3    0    0    0\n",
       "6        2    1    0    1    0    1  433    0    0    0\n",
       "7        0    1    1    0    0    0    0  458    0    0\n",
       "8        0    0    1    0    0    1    0    0  422    1\n",
       "9        0    0    0    0    5    1    0    1    1  388"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.sum(test_probs, axis=0).argmax(axis=1)\n",
    "pd.crosstab(y_test.idxmax(axis=1), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.991904761904762"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test.idxmax(axis=1) == preds).sum() / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40338</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24095</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33701</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13232</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9\n",
       "40338  0  0  0  0  0  0  0  0  0  1\n",
       "24095  0  0  0  0  0  0  0  0  0  1\n",
       "32205  0  0  0  0  0  1  0  0  0  0\n",
       "33701  0  1  0  0  0  0  0  0  0  0\n",
       "13232  1  0  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 5, ..., 6, 6, 8], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4200,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
