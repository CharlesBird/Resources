{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential 顺序模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\PythonDevelopers\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多分类问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 二分类问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 均方误差回归问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\n",
    "# 自定义评估标准函数\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\PythonDevelopers\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 645us/step - loss: 0.7044 - acc: 0.5210\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 0.6955 - acc: 0.5470\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.6915 - acc: 0.5200\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 39us/step - loss: 0.6882 - acc: 0.5460\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 44us/step - loss: 0.6844 - acc: 0.5620\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 0.6804 - acc: 0.5590\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6785 - acc: 0.5770\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 40us/step - loss: 0.6749 - acc: 0.5780\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 0.6714 - acc: 0.5820\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 46us/step - loss: 0.6671 - acc: 0.5910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d3b406c88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于具有 2 个类的单输入模型（二进制分类）：\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 481us/step - loss: 2.3646 - acc: 0.0860\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 41us/step - loss: 2.3244 - acc: 0.1040\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.3087 - acc: 0.1210\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 2.2972 - acc: 0.1200\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 63us/step - loss: 2.2880 - acc: 0.1380\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 60us/step - loss: 2.2792 - acc: 0.1330: 0s - loss: 2.2783 - acc: 0.134\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 47us/step - loss: 2.2727 - acc: 0.1520\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 48us/step - loss: 2.2628 - acc: 0.1460\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 43us/step - loss: 2.2577 - acc: 0.1500\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 42us/step - loss: 2.2481 - acc: 0.1580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d3b7b4c50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于具有 10 个类的单输入模型（多分类分类）：\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "# 将标签转换为分类的 one-hot 编码\n",
    "one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)\n",
    "\n",
    "# 训练模型，以 32 个样本为一个 batch 进行迭代\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于多层感知器 (MLP) 的 softmax 多分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\PythonDevelopers\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 1s 646us/step - loss: 2.3804 - acc: 0.0970\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3563 - acc: 0.1000\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 16us/step - loss: 2.3335 - acc: 0.1000\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 28us/step - loss: 2.3388 - acc: 0.0940\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 2.3228 - acc: 0.1130\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 27us/step - loss: 2.3146 - acc: 0.0960\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3075 - acc: 0.1000\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 14us/step - loss: 2.3065 - acc: 0.1010\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 2.3028 - acc: 0.1140\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 2.3028 - acc: 0.1120\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 2.3051 - acc: 0.1080\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 25us/step - loss: 2.3089 - acc: 0.1100\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 2.2949 - acc: 0.1140\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.3051 - acc: 0.1090\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.2948 - acc: 0.1260\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 19us/step - loss: 2.3036 - acc: 0.1000\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 2.3076 - acc: 0.1000\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 2.2996 - acc: 0.1130\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 16us/step - loss: 2.2992 - acc: 0.1150\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 2.2982 - acc: 0.1200\n",
      "100/100 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 生成虚拟数据\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) 是一个具有 64 个隐藏神经元的全连接层。\n",
    "# 在第一层必须指定所期望的输入数据尺寸：\n",
    "# 在这里，是一个 20 维的向量。\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于多层感知器的二分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 1s 809us/step - loss: 0.7080 - acc: 0.4910\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 0.7112 - acc: 0.4960\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 0.7103 - acc: 0.4780\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.6990 - acc: 0.5080\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 16us/step - loss: 0.7046 - acc: 0.4540\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 16us/step - loss: 0.6980 - acc: 0.4920\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 33us/step - loss: 0.6924 - acc: 0.5040\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.6955 - acc: 0.5140\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.6982 - acc: 0.5080\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 0.6989 - acc: 0.5050\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 0.6925 - acc: 0.5190\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 22us/step - loss: 0.6950 - acc: 0.5120\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.6912 - acc: 0.5280\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 21us/step - loss: 0.6916 - acc: 0.5220\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 29us/step - loss: 0.6967 - acc: 0.5120\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 0.6910 - acc: 0.5260\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.6907 - acc: 0.5300\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 23us/step - loss: 0.6934 - acc: 0.5120\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 0.6912 - acc: 0.5200\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 24us/step - loss: 0.6960 - acc: 0.5030\n",
      "100/100 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# 生成虚拟数据\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = np.random.randint(2, size=(1000, 1))\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类似 VGG 的卷积神经网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 2.3173\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 2.3865\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.2926\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.3149\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.3232\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 2.2905\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.2811\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 2.2761\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.2911\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 2.2855\n",
      "20/20 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 生成虚拟数据\n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# 输入: 3 通道 100x100 像素图像 -> (100, 100, 3) 张量。\n",
    "# 使用 32 个大小为 3x3 的卷积滤波器。\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 LSTM 的序列分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 5s 0us/step\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n",
      "Build model...\n",
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 128s 5ms/step - loss: 0.4599 - acc: 0.7834 - val_loss: 0.3879 - val_acc: 0.8336\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 130s 5ms/step - loss: 0.2991 - acc: 0.8775 - val_loss: 0.3674 - val_acc: 0.8376\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 147s 6ms/step - loss: 0.2164 - acc: 0.9162 - val_loss: 0.4523 - val_acc: 0.8025\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 126s 5ms/step - loss: 0.1578 - acc: 0.9400 - val_loss: 0.4523 - val_acc: 0.8318\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 124s 5ms/step - loss: 0.1045 - acc: 0.9628 - val_loss: 0.6102 - val_acc: 0.8213\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 127s 5ms/step - loss: 0.0765 - acc: 0.9739 - val_loss: 0.7214 - val_acc: 0.8221\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 129s 5ms/step - loss: 0.0608 - acc: 0.9793 - val_loss: 0.8516 - val_acc: 0.8132\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 132s 5ms/step - loss: 0.0404 - acc: 0.9867 - val_loss: 0.8184 - val_acc: 0.8155\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 124s 5ms/step - loss: 0.0279 - acc: 0.9910 - val_loss: 0.8328 - val_acc: 0.8173\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 125s 5ms/step - loss: 0.0317 - acc: 0.9891 - val_loss: 0.9131 - val_acc: 0.8071\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 119s 5ms/step - loss: 0.0277 - acc: 0.9908 - val_loss: 0.8797 - val_acc: 0.8162\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 120s 5ms/step - loss: 0.0154 - acc: 0.9955 - val_loss: 1.0797 - val_acc: 0.8130\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 120s 5ms/step - loss: 0.0110 - acc: 0.9966 - val_loss: 1.0982 - val_acc: 0.8140\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 119s 5ms/step - loss: 0.0101 - acc: 0.9969 - val_loss: 1.0798 - val_acc: 0.8121\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 121s 5ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 1.1140 - val_acc: 0.8097\n",
      "25000/25000 [==============================] - 24s 954us/step\n",
      "Test score: 1.11400374132514\n",
      "Test accuracy: 0.80972\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "\n",
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于栈式 LSTM 的序列分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 11.6066 - acc: 0.0850 - val_loss: 11.6028 - val_acc: 0.1300\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 429us/step - loss: 11.6047 - acc: 0.1000 - val_loss: 11.6044 - val_acc: 0.1000\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 421us/step - loss: 11.6048 - acc: 0.1070 - val_loss: 11.6048 - val_acc: 0.0600\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 428us/step - loss: 11.6039 - acc: 0.1090 - val_loss: 11.6025 - val_acc: 0.0900\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 428us/step - loss: 11.6038 - acc: 0.1060 - val_loss: 11.6052 - val_acc: 0.0800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d04cf6b70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "\n",
    "# 期望输入数据尺寸: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # 返回维度为 32 的向量序列\n",
    "model.add(LSTM(32, return_sequences=True))  # 返回维度为 32 的向量序列\n",
    "model.add(LSTM(32))  # 返回维度为 32 的单个向量\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟训练数据\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# 生成虚拟验证数据\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=5,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"stateful\" 渲染的的栈式 LSTM 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 320 samples, validate on 96 samples\n",
      "Epoch 1/5\n",
      "320/320 [==============================] - 5s 16ms/step - loss: 11.5609 - acc: 0.1031 - val_loss: 11.6017 - val_acc: 0.1562\n",
      "Epoch 2/5\n",
      "320/320 [==============================] - 0s 345us/step - loss: 11.5567 - acc: 0.1094 - val_loss: 11.6018 - val_acc: 0.1771\n",
      "Epoch 3/5\n",
      "320/320 [==============================] - 0s 355us/step - loss: 11.5559 - acc: 0.1156 - val_loss: 11.6017 - val_acc: 0.1771\n",
      "Epoch 4/5\n",
      "320/320 [==============================] - 0s 329us/step - loss: 11.5551 - acc: 0.1156 - val_loss: 11.6016 - val_acc: 0.1771\n",
      "Epoch 5/5\n",
      "320/320 [==============================] - 0s 344us/step - loss: 11.5544 - acc: 0.1125 - val_loss: 11.6016 - val_acc: 0.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d0d5107f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "\n",
    "# 期望输入数据尺寸: (batch_size, timesteps, data_dim)\n",
    "# 请注意，我们必须提供完整的 batch_input_shape，因为网络是有状态的。\n",
    "# 第 k 批数据的第 i 个样本是第 k-1 批数据的第 i 个样本的后续。\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True,\n",
    "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "model.add(LSTM(32, return_sequences=True, stateful=True))\n",
    "model.add(LSTM(32, stateful=True))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 生成虚拟训练数据\n",
    "x_train = np.random.random((batch_size * 10, timesteps, data_dim))\n",
    "y_train = np.random.random((batch_size * 10, num_classes))\n",
    "\n",
    "# 生成虚拟验证数据\n",
    "x_val = np.random.random((batch_size * 3, timesteps, data_dim))\n",
    "y_val = np.random.random((batch_size * 3, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size, epochs=5, shuffle=False,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
